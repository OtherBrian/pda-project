{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement\n",
    "For this project you must create a data set by simulating a real-world phenomenon of\n",
    "your choosing. You may pick any phenomenon you wish – you might pick one that is\n",
    "of interest to you in your personal or professional life. Then, rather than collect data\n",
    "related to the phenomenon, you should model and synthesise such data using Python.\n",
    "We suggest you use the numpy.random package for this purpose.\n",
    "Specifically, in this project you should:\n",
    "\n",
    "* Choose a real-world phenomenon that can be measured and for which you could\n",
    "collect at least one-hundred data points across at least four different variables.\n",
    "* Investigate the types of variables involved, their likely distributions, and their\n",
    "relationships with each other.\n",
    "* Synthesise/simulate a data set as closely matching their properties as possible.\n",
    "* Detail your research and implement the simulation in a Jupyter notebook – the\n",
    "data set itself can simply be displayed in an output cell within the notebook.\n",
    "\n",
    "Note that this project is about simulation – you must synthesise a data set. Some\n",
    "students may already have some real-world data sets in their own files. It is okay to\n",
    "base your synthesised data set on these should you wish (please reference it if you do),\n",
    "but the main task in this project is to create a synthesised data set. The next section\n",
    "gives an example project idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial thoughts - Only a fraction of International students in China get to the HSK 5 or 6.\n",
    "\n",
    "Despite the large number of international students in China, the minority attempt a standardized test (HSK). Even then, the bulk of people that do these tests go for HSK 4 or HSK 5, with HSK 6 having a noticable drop off. This is likely due to HSK 5 being an entry requirement for most college degrees in China, and so anything below HSK 4 or 5 is seen as having little value, whereas the exponential difficulty gap between each level means that HSK 6 is a large commitment to aim towards. Of those that do attempt the HSK though, the pass rate is quite high - likely due to preparation classes available as extras in Chinese universities and schools.\n",
    "\n",
    "I will also be highlighting the distribution of countries that students come from, with South Korea being the clear leader.\n",
    "\n",
    "\n",
    "## Variables\n",
    "\n",
    "* HSK level (see if I can get statistics on how many are awarded)\n",
    "* Origin country\n",
    "* Funding of study\n",
    "* Level of program they enroll into\n",
    "* Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country of Origin\n",
    "\n",
    "Turns out I only have access to the top 15 countries from 2018\n",
    "\n",
    "* South Korea\t50,600\n",
    "* Thailand\t28,608\n",
    "* Pakistan\t28,023\n",
    "* India\t23,198\n",
    "* United States\t20,996\n",
    "* Russia\t19,239\n",
    "* Indonesia\t15,050\n",
    "* Laos\t14,645\n",
    "* Japan\t14,230\n",
    "* Kazakhstan\t11,784\n",
    "* Vietnam\t11,299\n",
    "* Bangladesh\t10,735\n",
    "* France\t10,695\n",
    "* Mongolia\t10,158\n",
    "* Malaysia\t9,479"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.researchcghe.org/perch/resources/publications/to-publish-wp46.pdf\n",
    "\n",
    "Also has top 10 countries 2000-2016, and total international students. As I have HSK test data from 2012, if I follow these proportions I could estimate how many American students took on each of the tests. If I use the normal distribution of scores based on the earlier paper, I could simulate what students took on the HSK, what level and what score.\n",
    "\n",
    "It also has the % of students enrolled in fulltime degrees, etc. I know most degrees require HSK 5 at least in order to enrol, so I could extrapolate this out to make an educated guess on the number % of students in Chinese Language undergraduate degrees, as undergraduate Chinese language degrees would not require a HSK to enroll.\n",
    "\n",
    "It also shows how many students were receiving scholarships until 2013, and what proportion were for non-degree students. If I were to assume it grew at about the same rate as overall international students, and that it's shared proportionally between students from various countries, I could look at who was self-funded versus on scholarship.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2018 there were 492,185 International Students in China (http://global.chinadaily.com.cn/a/201904/12/WS5cb05c3ea3104842260b5eed.html#:~:text=Almost%20500%2C000%20international%20students%20studied,ministry%20said%20in%20a%20statement.)\n",
    "\n",
    "So based off of that number and the above breakdown we know that 278739 came from those 15 countries, therefore 213446 would come from \"Rest of the World\". At present I do not have a way to break these down further. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "I've since found that there were 81,562 African students in China in 2018 (https://www.studyinternational.com/news/african-students-china-alienated/). There's no breakdown by country though. This would bring rest of the world down to 131884.\n",
    "\n",
    "* Rest of the World 131,884\n",
    "* Africa 81,562\n",
    "* South Korea\t50,600\n",
    "* Thailand\t28,608\n",
    "* Pakistan\t28,023\n",
    "* India\t23,198\n",
    "* United States\t20,996\n",
    "* Russia\t19,239\n",
    "* Indonesia\t15,050\n",
    "* Laos\t14,645\n",
    "* Japan\t14,230\n",
    "* Kazakhstan\t11,784\n",
    "* Vietnam\t11,299\n",
    "* Bangladesh\t10,735\n",
    "* France\t10,695\n",
    "* Mongolia\t10,158\n",
    "* Malaysia\t9,479\n",
    "\n",
    "Going to work out proportions from each country\n",
    "\n",
    "World Population Dataset from https://data.worldbank.org/indicator/SP.POP.TOTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting African and Rest of the World countries.\n",
    "\n",
    "I'm going to use data from the World Bank to find out what proportion of the African population each country of African has, and I'll use this as the probability of the student coming from that country. This isn't a perfect measure, as in the real world there'd be political and academic exchanges with particular countries, meanwhile some countries are more likely to have a population that can afford to go to China for self-funded study. Nonetheless, I prefer this route as I do not want the 54 countries of African treated as one unit.\n",
    "\n",
    "I will also be doing the same for the Rest of the World. This comes with the same caveats as the African countries in that they do not represent academic or political exchanges. That said, the countries with large populations that are not counted in this top 15 or the African countries do tend to have populations that may afford studying abroad. For example Germany would be one of the remaining countries with a larger population, and so it's probability will be higher than others, however in real life its population is also likely to be more able to afford self-funded study in China."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can alter this to change the school size.\n",
    "school_size = 2000\n",
    "\n",
    "#Likewise the seed can be edited to get different results.\n",
    "seed = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#read_csv documentation https://pandas.pydata.org/pandas-docs/dev/reference/api/pandas.read_csv.html\n",
    "#I've edited this dataset to remove aggregations (e.g. Eurozone, World).\n",
    "#as well as China, Hong Kong and Macau - as these would not be considered International Students.\n",
    "populations_df = pd.read_csv('world_populations.csv', usecols = ['Country Name', 'Country Code', '2019'])\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "populations_df.dropna(inplace=True)\n",
    "\n",
    "populations_df['2019'] = populations_df['2019'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Country Codes\n",
    "african_country_codes = ['DZA','AGO','BWA','IOT','BDI','CMR','CPV','CAF','TCD',\n",
    "                     'COM','MYT','COG','COD','BEN','GNQ','ETH','ERI','ATF',\n",
    "                     'DJI','GAB','GMB','GHA','GIN','CIV','KEN','LSO','LBR',\n",
    "                     'LBY','MDG','MWI','MLI','MRT','MUS','MAR','MOZ','NAM',\n",
    "                     'NER','NGA','GNB','REU','RWA','SHN','STP','SEN','SYC',\n",
    "                     'SLE','SOM','ZAF','ZWE','SSD','SDN','ESH','SWZ','TGO',\n",
    "                     'TUN','UGA','EGY','TZA','BFA','ZMB']\n",
    "\n",
    "\n",
    "#Slicing the dataframe to only include countries with the african_country_codes.\n",
    "#I'll then dive the individual country's population in 2019 by the total for all the African countries to get the proportion.\n",
    "populations_df.loc[populations_df['Country Code'].isin(african_country_codes), 'Proportion of African Population'] = populations_df['2019'] / populations_df.loc[populations_df['Country Code'].isin(african_country_codes)]['2019'].sum()\n",
    "\n",
    "populations_df.loc[populations_df['Country Code'].isin(african_country_codes)].head()\n",
    "\n",
    "#Turning the list of African countries and their probabilities into arrays to use later.\n",
    "african_country = np.array(populations_df.loc[populations_df['Country Code'].isin(african_country_codes)]['Country Name'])\n",
    "african_probabilities = np.array(populations_df.loc[populations_df['Country Code'].isin(african_country_codes)]['Proportion of African Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to remove the top 15 countries from rest of the world too.\n",
    "#I'll first state what those top 15 country codes are.\n",
    "top_15_country_codes = ['KOR', 'THA', 'PAK', 'IND', 'USA', 'RUS', 'IDN', 'LAO', 'JPN', 'KAZ', 'VNM', 'BGD', 'FRA', 'MNG', 'MYS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 15 countries combined population.\n",
    "top_15_total_population = populations_df.loc[populations_df['Country Code'].isin(top_15_country_codes)]['2019'].sum()\n",
    "\n",
    "#African countries combined population.\n",
    "africa_total_population = populations_df.loc[populations_df['Country Code'].isin(african_country_codes)]['2019'].sum()\n",
    "\n",
    "#World Population without China, Hong Kong & Macau, minus the African population, minus the top 15 countries\n",
    "rest_of_world_population = 6267671127 - africa_total_population - top_15_total_population\n",
    "\n",
    "#Removing the African countries and Top 15 countries from the rest_of_world slice.\n",
    "rest_of_world = populations_df.loc[~populations_df['Country Code'].isin(african_country_codes)]\n",
    "rest_of_world = rest_of_world.loc[~rest_of_world['Country Code'].isin(top_15_country_codes)]\n",
    "\n",
    "#Working out the proportions for each country.\n",
    "rest_of_world['Proportion of World Population'] = rest_of_world['2019'] / rest_of_world_population\n",
    "\n",
    "#Turning the list of countries and their probabilities into arrays to use later.\n",
    "rest_of_world_country = np.array(rest_of_world['Country Name'])\n",
    "rest_of_world_probabilities = np.array(rest_of_world['Proportion of World Population'])\n",
    " \n",
    "#At present, the probabilities for rest of the world do not equal 1. I will therefore fill the gap and assign it as \"Other\".\n",
    "other = 1 - sum(rest_of_world_probabilities)\n",
    "\n",
    "#Add \"Other\" into the selection and probabilties\n",
    "rest_of_world_country = np.insert(rest_of_world_country, -1, 'Other')\n",
    "rest_of_world_probabilities = np.insert(rest_of_world_probabilities, -1,  other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the probabilities and country names set up for the African and Rest of the World countries, I can use np.random.choice() to pick a student origin from the 17 regions (top 15 countries, Africa and Rest of the world). If Africa or Rest of the World is selected, it can then pick a country from those subsections.\n",
    "\n",
    "Now I'll need to get the probabilities of each of the 17 regions to be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html#numpy.random.Generator.choice\n",
    "\n",
    "#State the list of possible countries to be selected by Choice()\n",
    "student_origins = np.array(['Rest of the World', 'Africa', 'South Korea', 'Thailand', 'Pakistan', 'India', 'United States',\n",
    "                  'Russia', 'Indonesia', 'Laos', 'Japan', 'Kazakhstan', 'Vietnam', 'Bangladesh', 'France', 'Mongolia',\n",
    "                  'Malaysia'])\n",
    "\n",
    "#Count of students from each region in 2018.\n",
    "student_origin_counts = np.array([131884, 81562, 50600, 28608, 28023, 23198, 20996, 19239, 15050, 14645, 14230, 11784,\n",
    "                        11299, 10735, 10695, 10158, 9479])\n",
    "\n",
    "\n",
    "#Work out the probability that a student came from each region by its proportion to the total.\n",
    "student_origin_probabilities = student_origin_counts / sum(student_origin_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll use Choice() to select a country for each student. Choice() will select option (with replacement) from student_origins, the number of selections is decided by the value of school_size, and the probability of each option beng selected is determined by student_origin_probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pakistan', 'Africa', 'Pakistan', ..., 'Rest of the World',\n",
       "       'United States', 'Rest of the World'], dtype='<U17')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "students = rng.choice(student_origins, school_size, p=student_origin_probabilities)\n",
    "\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nationality  \n",
       "South Korea      216\n",
       "Thailand         111\n",
       "Pakistan          99\n",
       "United States     98\n",
       "India             84\n",
       "                ... \n",
       "Congo, Rep.        1\n",
       "Lebanon            1\n",
       "Croatia            1\n",
       "Latvia             1\n",
       "Zimbabwe           1\n",
       "Length: 142, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "#Creating an index of student IDs to use for this\n",
    "index = np.arange(0,school_size)\n",
    "\n",
    "#Create the dataframe\n",
    "chinese_class_df = pd.DataFrame(index = index, columns = ['Nationality'])\n",
    "#Generate the countries\n",
    "chinese_class_df['Nationality'] = rng.choice(student_origins, school_size, p=student_origin_probabilities)\n",
    "\n",
    "#https://stackoverflow.com/questions/49471442/using-pandas-value-counts-to-get-one-value\n",
    "#Iterating over rows\n",
    "#African students have a country picked for them\n",
    "chinese_class_df.loc[chinese_class_df['Nationality'] == 'Africa', 'Nationality'] = rng.choice(african_country, (chinese_class_df['Nationality'].values == 'Africa').sum(), p=african_probabilities) \n",
    "\n",
    "#Rest of the world students have a country picked for them\n",
    "chinese_class_df.loc[chinese_class_df['Nationality'] == 'Rest of the World', 'Nationality'] = rng.choice(rest_of_world_country, (chinese_class_df['Nationality'].values == 'Rest of the World').sum(), p=rest_of_world_probabilities) \n",
    "\n",
    "chinese_class_df.value_counts()\n",
    "#african_students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who sat the HSK tests?\n",
    "\n",
    "Use 2012 figures for HSK test compared to International Students in China. Extrapolate what those numbers would be for 2018. Use the proportion that sat the tests as the success probability for a bernoulli distribution (via np.random.binomial).\n",
    "\n",
    "Taken from Sina Weibo: 2009-2012 HSK takers - http://blog.sina.com.cn/s/blog_53e7c11d0101f02j.html\n",
    "![here](https://screenshot.click/01_14-ryey4-tgwud.jpg)\n",
    "\n",
    "Important to note that the current version of the HSK tests was introduced in 2010, so a sharp increase in the first few years isn't a surprise. (Wikipedia references the history - https://en.wikipedia.org/wiki/Hanyu_Shuiping_Kaoshi#Between_2010%E2%80%932020)\n",
    "\n",
    "Also worthwhile noting that the table above doesn't specify students that took multiple HSK tests. For example someone could reasonably do HSK 1, 2 and 3 within the same year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the numbers that sat the test within China (国内).\n",
    "\n",
    "First let's look at the written HSK exams.\n",
    "* HSK 一级\n",
    "* HSK 二级\n",
    "* HSK 三级\n",
    "* HSK 四级\n",
    "* HSK 五级\n",
    "* HSK 六级\n",
    "\n",
    "I'm going to calculate the annual total written HSK tests taken in each of these years, and compare to the number of international students in China for each year (from page 36 of https://www.researchcghe.org/perch/resources/publications/to-publish-wp46.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total students taking HSK written exam in 2010: 17866\n",
      "Total students taking HSK written exam in 2011: 46161\n",
      "Total students taking HSK written exam in 2012: 60593\n",
      "Proportion of international students taking HSK written exam in 2010: 0.06739597872420687\n",
      "Proportion of international students taking HSK written exam in 2011: 0.15775551841865137\n",
      "Proportion of international students taking HSK written exam in 2012: 0.18454908171656564\n"
     ]
    }
   ],
   "source": [
    "hsk_written_2010 = 146 + 210 + 1171 + 3842 + 6931 + 5566\n",
    "hsk_written_2011 = 274 + 755 + 2504 + 11635 + 18018 + 12975\n",
    "hsk_written_2012 = 658 + 1343 + 4003 + 16158 + 21278 + 17153\n",
    "\n",
    "print(\"Total students taking HSK written exam in 2010: \" + str(hsk_written_2010))\n",
    "print(\"Total students taking HSK written exam in 2011: \" + str(hsk_written_2011))\n",
    "print(\"Total students taking HSK written exam in 2012: \" + str(hsk_written_2012))\n",
    "\n",
    "total_international_students_2010 = 265090\n",
    "total_international_students_2011 = 292611\n",
    "total_international_students_2012 = 328330\n",
    "\n",
    "print(\"Proportion of international students taking HSK written exam in 2010: \" + str(hsk_written_2010 / total_international_students_2010))\n",
    "print(\"Proportion of international students taking HSK written exam in 2011: \" + str(hsk_written_2011 / total_international_students_2011))\n",
    "print(\"Proportion of international students taking HSK written exam in 2012: \" + str(hsk_written_2012 / total_international_students_2012))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 2012 is the latest year I can find for these types of figures, I will extrapolate the 2012 proportion to the number of international students in 2018. \n",
    "\n",
    "There were 492,185 international students in 2018, and if 18.5% took a HSK test we can expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated total students taking HSK written exam in 2018: 91054.0\n"
     ]
    }
   ],
   "source": [
    "hsk_written_total_2018 = 492185 * 0.185\n",
    "print(\"Estimated total students taking HSK written exam in 2018: \" + str(round(hsk_written_total_2018,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see how many of my students sat a written HSK exam in 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1637\n",
       "1     363\n",
       "Name: HSK written test?, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "#https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.binomial.html#numpy.random.Generator.binomial\n",
    "chinese_class_df['HSK written test?'] = rng.binomial(1, 0.185, school_size)\n",
    "\n",
    "chinese_class_df['HSK written test?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the oral exams\n",
    "* HSK 初级\n",
    "* HSK 中级\n",
    "* HSK 高级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total students taking HSK oral exam in 2010: 1023\n",
      "Total students taking HSK oral exam in 2011: 1886\n",
      "Total students taking HSK oral exam in 2012: 3171\n",
      "Proportion of international students taking HSK oral exam in 2010: 0.0038590667320532648\n",
      "Proportion of international students taking HSK oral exam in 2011: 0.00644541729463349\n",
      "Proportion of international students taking HSK oral exam in 2012: 0.00965796607072153\n"
     ]
    }
   ],
   "source": [
    "hsk_oral_2010 = 51 + 300 + 672\n",
    "hsk_oral_2011 = 67 + 506 + 1313\n",
    "hsk_oral_2012 = 56 + 1708 + 1407\n",
    "\n",
    "print(\"Total students taking HSK oral exam in 2010: \" + str(hsk_oral_2010))\n",
    "print(\"Total students taking HSK oral exam in 2011: \" + str(hsk_oral_2011))\n",
    "print(\"Total students taking HSK oral exam in 2012: \" + str(hsk_oral_2012))\n",
    "\n",
    "total_international_students_2010 = 265090\n",
    "total_international_students_2011 = 292611\n",
    "total_international_students_2012 = 328330\n",
    "\n",
    "print(\"Proportion of international students taking HSK oral exam in 2010: \" + str(hsk_oral_2010 / total_international_students_2010))\n",
    "print(\"Proportion of international students taking HSK oral exam in 2011: \" + str(hsk_oral_2011 / total_international_students_2011))\n",
    "print(\"Proportion of international students taking HSK oral exam in 2012: \" + str(hsk_oral_2012 / total_international_students_2012))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I'll use the 2012 figure, and round it up to 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated total students taking HSK oral exam in 2018: 4922.0\n"
     ]
    }
   ],
   "source": [
    "hsk_oral_total_2018 = 492185 * 0.01\n",
    "print(\"Estimated total students taking HSK oral exam in 2018: \" + str(round(hsk_oral_total_2018,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see how many of my students sat the HSK oral exam in 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1974\n",
       "1      26\n",
       "Name: HSK oral test?, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "#https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.binomial.html#numpy.random.Generator.binomial\n",
    "chinese_class_df['HSK oral test?'] = rng.binomial(1, 0.01, school_size)\n",
    "\n",
    "chinese_class_df['HSK oral test?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did any students sit both the written and oral exams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>HSK written test?</th>\n",
       "      <th>HSK oral test?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>South Korea</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>Philippines</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Nationality  HSK written test?  HSK oral test?\n",
       "368      Thailand                  1               1\n",
       "459        France                  1               1\n",
       "839         India                  1               1\n",
       "902         India                  1               1\n",
       "1212       Canada                  1               1\n",
       "1650  South Korea                  1               1\n",
       "1725  Philippines                  1               1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_class_df.loc[(chinese_class_df['HSK written test?'] == 1) & (chinese_class_df['HSK oral test?'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who sat which exam?\n",
    "\n",
    "Look at the proportion of folks that did Hsk 1-6, and HSK beginner-advanced to use as probabilities. If a student has 1 in the oral or written test columns, np.random.choice based on the probabilities. As I'll be extrapolating 2012 figures for 2018, I'll use the 2012 ratios here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01085934, 0.02216428, 0.06606374, 0.26666447, 0.35116268,\n",
       "       0.2830855 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the 2012 figures to work out what proportion of HSK takers sat each level that year.\n",
    "\n",
    "#Listing the 6 HSK levels for the written exam\n",
    "hsk_written_levels = np.array(['HSK1', 'HSK2', 'HSK3', 'HSK4', 'HSK5', 'HSK6'])\n",
    "\n",
    "#Dividing the 2012 figures for each level by total HSK tests taken that year. These proportions will be my probabilities\n",
    "hsk_written_levels_proportions = np.array([658, 1343, 4003, 16158, 21278, 17153]) / hsk_written_2012\n",
    "\n",
    "hsk_written_levels_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these proportions to estimate how many of our estimated 91054 HSK written exam takers took each level in 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated HSK 1 takers in 2018: 989.0\n",
      "Estimated HSK 2 takers in 2018: 2018.0\n",
      "Estimated HSK 3 takers in 2018: 6015.0\n",
      "Estimated HSK 4 takers in 2018: 24281.0\n",
      "Estimated HSK 5 takers in 2018: 31975.0\n",
      "Estimated HSK 6 takers in 2018: 25776.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated HSK 1 takers in 2018: \" + str(round(hsk_written_levels_proportions[0] * 91054, 0)))\n",
    "print(\"Estimated HSK 2 takers in 2018: \" + str(round(hsk_written_levels_proportions[1] * 91054, 0)))\n",
    "print(\"Estimated HSK 3 takers in 2018: \" + str(round(hsk_written_levels_proportions[2] * 91054, 0)))\n",
    "print(\"Estimated HSK 4 takers in 2018: \" + str(round(hsk_written_levels_proportions[3] * 91054, 0)))\n",
    "print(\"Estimated HSK 5 takers in 2018: \" + str(round(hsk_written_levels_proportions[4] * 91054, 0)))\n",
    "print(\"Estimated HSK 6 takers in 2018: \" + str(round(hsk_written_levels_proportions[5] * 91054, 0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to use these proportions as my probabilities to estimate what level each of my school's HSK takers attempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HSK5    142\n",
       "HSK6    105\n",
       "HSK4     80\n",
       "HSK3     25\n",
       "HSK2      9\n",
       "HSK1      2\n",
       "Name: HSK Level, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only want students that have \"HSK written test?\" set as 1. First count how many there are to use as the size for rng.choice()\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK written test?'] == 1, 'HSK Level'] = rng.choice(hsk_written_levels, chinese_class_df['HSK written test?'].sum(), p=hsk_written_levels_proportions) \n",
    "\n",
    "chinese_class_df['HSK Level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to do the same for the oral test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01766004, 0.53863135, 0.44370861])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsk_oral_levels = np.array(['Beginner', 'Intermediate', 'Advanced'])\n",
    "hsk_oral_level_proportions = np.array([56, 1708, 1407]) / hsk_oral_2012\n",
    "\n",
    "hsk_oral_level_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, let's extrapolate this our for 2018. Early I estimated 4922 people sat a HSK oral test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated HSK Beginner takers in 2018: 87.0\n",
      "Estimated HSK Intermediate takers in 2018: 2651.0\n",
      "Estimated HSK Advanced takers in 2018: 2184.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated HSK Beginner takers in 2018: \" + str(round(hsk_oral_level_proportions[0] * 4922, 0)))\n",
    "print(\"Estimated HSK Intermediate takers in 2018: \" + str(round(hsk_oral_level_proportions[1] * 4922, 0)))\n",
    "print(\"Estimated HSK Advanced takers in 2018: \" + str(round(hsk_oral_level_proportions[2] * 4922, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see which oral tests the students in my school took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Advanced        15\n",
       "Intermediate    11\n",
       "Name: HSK Oral Level, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only want students that have \"HSK oral test?\" set as 1. First count how many there are to use as the size for rng.choice()\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK oral test?'] == 1, 'HSK Oral Level'] = rng.choice(hsk_oral_levels, chinese_class_df['HSK oral test?'].sum(), p=hsk_oral_level_proportions) \n",
    "\n",
    "chinese_class_df['HSK Oral Level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSK Results\n",
    "\n",
    "For those students that sat the HSK tests, we can now simulate what their scores might be. Finding data on HSK scores and results has proven to be very difficult (both in Chinese and in English), however according there has been a study on 108 American students and their HSK results before and after a semester of study in Beijing (https://www.researchgate.net/figure/Descriptive-statistics-of-general-proficiency-measured-by-HSK_tbl1_312107625). It should be noted that this paper covers just 108 students from the same country, so in reality there's likely to be numerous other variables that may impact the results seen by a particular student or even a whole cohort of students. For example, Chinese textbooks will have grammar and other explanations written in English for HSK 1 through to HSK 3, and the quality of those translations, or how comparable the grammar rules are to the readers native language may influence how well they retain the information and therefore perform on the test. \n",
    "\n",
    "Similarly, all 108 students in this study took the HSK 4 written test and the intermediate oral test, so we do not have comparable results for the various other levels. That said, all of the tests follow a similar marking structure, with each section scored out of 100, and so for the purposes of this assignment I will be utilising the mean and standard deviation that was found among those 108 students.\n",
    "\n",
    "This is by no means a perfect simulation of the scores that I can expect at my fictional school, but with the absence of data on HSK test scores or pass/fail rates, it will have to suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSK Written Test Results\n",
    "\n",
    "https://www.chinaeducenter.com/en/exams.php\n",
    "\n",
    "The HSK written tests follow a similar structure, with each level becoming more difficult. Levels 1 and 2 do not include a writing section, as students at this level are not expected to be able to hand write a large number of characters, and so reading and listening skills are the only areas tested. For levels 3 through to 6; reading, writing and listening are each tested.\n",
    "\n",
    "For levels 1-5, the student must achieve at least 60% in order to pass the test. For HSK level 6, only a score of 40% is required. The HSK tests are a simple pass/fail grading system.\n",
    "\n",
    "As each of the tests includes a reading and listening portion scored out of 100, and as I will be using the mean and standard deviation from the above linked study to simulate the results regardless of level, I can use the same function for all the written HSK takers. For this I will use a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    323\n",
       "0.0     29\n",
       "Name: HSK Pass, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading results https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.normal.html#numpy.random.Generator.normal\n",
    "\n",
    "reading_mean = 75.39\n",
    "reading_sd = 13.85\n",
    "chinese_class_df.loc[chinese_class_df['HSK written test?'] == 1, 'Reading'] = rng.normal(reading_mean, reading_sd, chinese_class_df['HSK written test?'].sum())\n",
    "\n",
    "#Reducing the HSK6 results by 1/3 to reflect the higher difficulty. The mean and SD for HSK4 is too high for this test.\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK Level'] == 'HSK6', ['Reading']] = (chinese_class_df['Reading'] / 3) * 2\n",
    "\n",
    "#Normal distribution will pick a few values above 100. This goes beyond the possible score in the section, so I'll cap these at 100.\n",
    "chinese_class_df.loc[chinese_class_df['Reading'] > 100, 'Reading'] = 100\n",
    "\n",
    "\n",
    "#Listening test\n",
    "listening_mean = 70.73\n",
    "listening_sd = 15.22\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK written test?'] == 1, 'Listening'] = rng.normal(listening_mean, listening_sd, chinese_class_df['HSK written test?'].sum())\n",
    "chinese_class_df.loc[chinese_class_df['HSK Level'] == 'HSK6', ['Listening']] = (chinese_class_df['Listening'] / 3) * 2\n",
    "chinese_class_df.loc[chinese_class_df['Listening'] > 100, 'Listening'] = 100\n",
    "\n",
    "\n",
    "#Only HSK 3 - 6 has a writing section, so I'll make a mask to help me subset those tests.\n",
    "hsk_writing_sections = ['HSK3', 'HSK4', 'HSK5', 'HSK6']\n",
    "\n",
    "writing_mean = 69.67\n",
    "writing_sd = 11.95\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK Level'].isin(hsk_writing_sections), 'Writing'] = rng.normal(writing_mean, writing_sd, len(chinese_class_df.loc[chinese_class_df['HSK Level'].isin(hsk_writing_sections)]))\n",
    "chinese_class_df.loc[chinese_class_df['HSK Level'] == 'HSK6', ['Writing']] = (chinese_class_df['Writing'] / 3) * 2\n",
    "chinese_class_df.loc[chinese_class_df['Writing'] > 100, 'Writing'] = 100\n",
    "\n",
    "#https://stackoverflow.com/questions/31247763/round-columns-in-pandas-dataframe\n",
    "\n",
    "chinese_class_df[['Reading', 'Listening', 'Writing']] = chinese_class_df[['Reading', 'Listening', 'Writing']].apply(pd.Series.round)\n",
    "\n",
    "#Combined the 3 sections to get the score\n",
    "chinese_class_df['Total Written Score'] = chinese_class_df['Reading'] + chinese_class_df['Listening'] + chinese_class_df['Writing']\n",
    "\n",
    "#HSK 3 - 6 has 3 sections, so final score has to be divided by 3.\n",
    "chinese_class_df.loc[chinese_class_df['HSK Level'].isin(hsk_writing_sections), 'Total Written Score'] = round(chinese_class_df['Total Written Score'] / 3, 2)\n",
    "\n",
    "chinese_class_df.loc[~chinese_class_df['HSK Level'].isin(hsk_writing_sections), 'Total Written Score'] = round(chinese_class_df['Total Written Score'] / 2, 2)\n",
    "\n",
    "hsk_pass_60_tests = ['HSK1','HSK2','HSK3','HSK4','HSK5']\n",
    "\n",
    "chinese_class_df.loc[(chinese_class_df['HSK Level'].isin(hsk_pass_60_tests)) & (chinese_class_df['Total Written Score'] >= 60), 'HSK Pass'] = 1\n",
    "chinese_class_df.loc[(chinese_class_df['HSK Level'].isin(hsk_pass_60_tests)) & (chinese_class_df['Total Written Score'] < 60), 'HSK Pass'] = 0\n",
    "chinese_class_df.loc[(~chinese_class_df['HSK Level'].isin(hsk_pass_60_tests)) & (chinese_class_df['Total Written Score'] >=40), 'HSK Pass'] = 1\n",
    "chinese_class_df.loc[(~chinese_class_df['HSK Level'].isin(hsk_pass_60_tests)) & (chinese_class_df['Total Written Score'] <40), 'HSK Pass'] = 0\n",
    "\n",
    "chinese_class_df['HSK Pass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSK Oral Test Results\n",
    "\n",
    "Unlike the written tests which have 2 or 3 distinct sections, the HSK Oral Test just tests spoken language skills, and so just has the 1 speaking section. The passing grade for this is 60% for all three levels of the oral test (beginner, intermiedate, advanced).\n",
    "\n",
    "The previous mentioned study for 108 students from the US also measured the results of the HSK Oral test for those students. One notable difference here is that due to the low participation rate of the HSK Oral test, a sample of 108 measurements is actually fairly sizable. Earlier in my extrapolation of 2012 trends to 2018 international student figures, we saw that only about 1% of students in China attempt the HSK Oral test. While the written HSK 4 is seen as the first valuable HSK certification, and HSK 5 is required for attending a college program in Chinese, the oral certifications have very few applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HSK written test?</th>\n",
       "      <th>HSK oral test?</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Listening</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Total Written Score</th>\n",
       "      <th>HSK Pass</th>\n",
       "      <th>Speaking</th>\n",
       "      <th>HSK Oral Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>363.000000</td>\n",
       "      <td>363.000000</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>64.140496</td>\n",
       "      <td>62.559659</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>0.940341</td>\n",
       "      <td>79.115385</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.385528</td>\n",
       "      <td>0.113302</td>\n",
       "      <td>17.012345</td>\n",
       "      <td>16.991372</td>\n",
       "      <td>15.599031</td>\n",
       "      <td>12.909037</td>\n",
       "      <td>0.237191</td>\n",
       "      <td>9.622170</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>53.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>67.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>74.250000</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>82.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HSK written test?  HSK oral test?     Reading   Listening     Writing  \\\n",
       "count        2000.000000     2000.000000  363.000000  363.000000  352.000000   \n",
       "mean            0.181500        0.013000   68.000000   64.140496   62.559659   \n",
       "std             0.385528        0.113302   17.012345   16.991372   15.599031   \n",
       "min             0.000000        0.000000   31.000000   25.000000   26.000000   \n",
       "25%             0.000000        0.000000   54.000000   50.000000   50.000000   \n",
       "50%             0.000000        0.000000   69.000000   64.000000   62.000000   \n",
       "75%             0.000000        0.000000   82.000000   77.000000   74.250000   \n",
       "max             1.000000        1.000000  100.000000  100.000000  100.000000   \n",
       "\n",
       "       Total Written Score    HSK Pass   Speaking  HSK Oral Pass  \n",
       "count           352.000000  352.000000  26.000000           26.0  \n",
       "mean             64.666667    0.940341  79.115385            1.0  \n",
       "std              12.909037    0.237191   9.622170            0.0  \n",
       "min              33.333333    0.000000  60.000000            1.0  \n",
       "25%              53.666667    1.000000  72.250000            1.0  \n",
       "50%              67.333333    1.000000  79.000000            1.0  \n",
       "75%              74.333333    1.000000  82.500000            1.0  \n",
       "max              94.000000    1.000000  99.000000            1.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsk_oral_mean = 79\n",
    "hsk_oral_sd = 9.84\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK oral test?'] == 1, 'Speaking'] = rng.normal(hsk_oral_mean, hsk_oral_sd, chinese_class_df['HSK oral test?'].sum())\n",
    "chinese_class_df.loc[chinese_class_df['Speaking'] > 100, 'Speaking'] = 100\n",
    "\n",
    "chinese_class_df[['Speaking']] = chinese_class_df[['Speaking']].apply(pd.Series.round)\n",
    "\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['Speaking'] >= 60, 'HSK Oral Pass'] = 1\n",
    "chinese_class_df.loc[chinese_class_df['Speaking'] < 60, 'HSK Oral Pass'] = 0\n",
    "\n",
    "\n",
    "chinese_class_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSK6 scores are too high. The mean for the HSK results is around 60, whereas pass for HSK6 is only 40. I will reduce the values by 1/3 to account for this.\n",
    "\n",
    "Also the scores need to be rounded. The normal distribution is a continuous one, so this isn't a surprise, especially as the standard deviation values are floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSK results\n",
    "\n",
    "https://www.researchgate.net/figure/Descriptive-statistics-of-general-proficiency-measured-by-HSK_tbl1_312107625\n",
    "\n",
    "108 participants from the US did the intermedite spoken exam and HSK 4 written exam.\n",
    "\n",
    "These students stayed in the country for 1 semester (about 3 months).\n",
    "\n",
    "We also have the mean, min, max and std from that group.\n",
    "\n",
    "![here](https://screenshot.click/28_19-215cg-skgcm.jpg)\n",
    "\n",
    "I could use this to create a normal distribution of test scores from US students who have been studying in China. As I know what a passing score is, I could calculate if it was a pass or fail.\n",
    "\n",
    "Another source of data on HSK 4 results http://dpi-proceedings.com/index.php/dtem/article/view/30976/29557\n",
    "\n",
    "Shows the mean and std for 30 students from Beijing Language & Culture University\n",
    "\n",
    "![here](https://screenshot.click/28_02-0i7p9-b37me.jpg)\n",
    "\n",
    "\n",
    "\n",
    "Some more results for 2010 including pass rates and average scores for each HSK level http://www.chinesetest.cn/gonewcontent.do?id=5589387 (Note - these are for tests taken outside China)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funding\n",
    "\n",
    "We know from http://en.moe.gov.cn/news/press_releases/201904/t20190418_378586.html that 63,041 received student scholarships from the Chinese government. This is 12.81% of the total International Students that year. For this we can use a bernoulli distribution (via the np.random.binomial function) to show who has a scholarship and who is self-funded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1739\n",
       "1     261\n",
       "Name: Scholarship, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Will use 1 to indicate a scholarship, and use the 12.81% figure from the government statistics.\n",
    "chinese_class_df['Scholarship'] = rng.binomial(1, 0.1281, school_size)\n",
    "chinese_class_df['Scholarship'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>HSK written test?</th>\n",
       "      <th>HSK oral test?</th>\n",
       "      <th>HSK Level</th>\n",
       "      <th>HSK Oral Level</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Listening</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Total Written Score</th>\n",
       "      <th>HSK Pass</th>\n",
       "      <th>Speaking</th>\n",
       "      <th>HSK Oral Pass</th>\n",
       "      <th>Scholarship</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Madagascar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nationality  HSK written test?  HSK oral test? HSK Level HSK Oral Level  \\\n",
       "0  Yemen, Rep.                  0               0       NaN            NaN   \n",
       "1     Thailand                  0               0       NaN            NaN   \n",
       "2   Madagascar                  0               0       NaN            NaN   \n",
       "3       Brazil                  0               0       NaN            NaN   \n",
       "4  South Korea                  0               0       NaN            NaN   \n",
       "\n",
       "   Reading  Listening  Writing  Total Written Score  HSK Pass  Speaking  \\\n",
       "0      NaN        NaN      NaN                  NaN       NaN       NaN   \n",
       "1      NaN        NaN      NaN                  NaN       NaN       NaN   \n",
       "2      NaN        NaN      NaN                  NaN       NaN       NaN   \n",
       "3      NaN        NaN      NaN                  NaN       NaN       NaN   \n",
       "4      NaN        NaN      NaN                  NaN       NaN       NaN   \n",
       "\n",
       "   HSK Oral Pass  Scholarship  \n",
       "0            NaN            0  \n",
       "1            NaN            0  \n",
       "2            NaN            0  \n",
       "3            NaN            0  \n",
       "4            NaN            0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_class_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of program\n",
    "\n",
    "According to http://en.moe.gov.cn/news/press_releases/201904/t20190418_378586.html 234,063 International students were not enrolled in degree programs. Of the 258,122 that were,  59,444 were in master's degrees and 25,618 were doctoral. THis means that 173,060 must have been undergraduate degrees. \n",
    "\n",
    "Unfortunately we do not have a breakdown on what areas these degrees would have been in. We know already that degrees taught in Chinese would require someone to already have HSK level 5 in order to join the course, however this requirement is not in place for students looking to study Chinese language. \n",
    "\n",
    "As my example is for a Chinese language school, I will therefore us these proportions as is. Postgraduate students could be coming to the school to learn Chinese alongside their existing languages or skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare the 4 types of programs available at the school.\n",
    "program_type = ['Non-degree', 'Undergraduate', \"Master's\", 'Doctoral']\n",
    "\n",
    "program_totals = np.array([234063, 173060, 59444, 25618])\n",
    "\n",
    "program_probabilities = program_totals / sum(program_totals)\n",
    "\n",
    "chinese_class_df['Program'] = rng.choice(program_type, school_size, p=program_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>HSK written test?</th>\n",
       "      <th>HSK oral test?</th>\n",
       "      <th>HSK Level</th>\n",
       "      <th>HSK Oral Level</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Listening</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Total Written Score</th>\n",
       "      <th>HSK Pass</th>\n",
       "      <th>Speaking</th>\n",
       "      <th>HSK Oral Pass</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Program</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Master's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Undergraduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Madagascar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Master's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South Korea</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HSK5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>70.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Doctoral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Iraq</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Master's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Haiti</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Master's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Doctoral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HSK2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HSK5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>78.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Laos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Undergraduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>South Korea</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HSK5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Master's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Congo, Dem. Rep.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HSK4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>64.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Undergraduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Russia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HSK5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Master's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Romania</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Master's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Doctoral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HSK5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>70.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Master's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Undergraduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Burundi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>South Sudan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Advanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HSK2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Undergraduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Nationality  HSK written test?  HSK oral test? HSK Level  \\\n",
       "0            Yemen, Rep.                  0               0       NaN   \n",
       "1               Thailand                  0               0       NaN   \n",
       "2             Madagascar                  0               0       NaN   \n",
       "3                 Brazil                  0               0       NaN   \n",
       "4            South Korea                  0               0       NaN   \n",
       "5            South Korea                  0               0       NaN   \n",
       "6            South Korea                  1               0      HSK5   \n",
       "7                  Japan                  0               0       NaN   \n",
       "8                   Iraq                  0               0       NaN   \n",
       "9                  Haiti                  0               0       NaN   \n",
       "10               Nigeria                  0               0       NaN   \n",
       "11         United States                  0               0       NaN   \n",
       "12              Thailand                  0               0       NaN   \n",
       "13                Turkey                  1               0      HSK2   \n",
       "14               Vietnam                  1               0      HSK5   \n",
       "15                  Laos                  0               0       NaN   \n",
       "16           South Korea                  1               0      HSK5   \n",
       "17      Congo, Dem. Rep.                  0               0       NaN   \n",
       "18           Netherlands                  1               0      HSK4   \n",
       "19                Russia                  1               0      HSK5   \n",
       "20               Vietnam                  0               0       NaN   \n",
       "21               Romania                  0               0       NaN   \n",
       "22             Indonesia                  0               0       NaN   \n",
       "23                Brazil                  1               0      HSK5   \n",
       "24             Indonesia                  0               0       NaN   \n",
       "25                Brazil                  0               0       NaN   \n",
       "26               Burundi                  0               0       NaN   \n",
       "27           South Sudan                  0               0       NaN   \n",
       "28          Saudi Arabia                  0               1       NaN   \n",
       "29  United Arab Emirates                  1               0      HSK2   \n",
       "\n",
       "   HSK Oral Level  Reading  Listening  Writing  Total Written Score  HSK Pass  \\\n",
       "0             NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "1             NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "2             NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "3             NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "4             NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "5             NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "6             NaN     66.0       83.0     63.0                70.67       1.0   \n",
       "7             NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "8             NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "9             NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "10            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "11            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "12            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "13            NaN     84.0       35.0      NaN                  NaN       NaN   \n",
       "14            NaN    100.0       68.0     67.0                78.33       1.0   \n",
       "15            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "16            NaN     78.0       45.0     59.0                60.67       1.0   \n",
       "17            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "18            NaN     56.0       67.0     71.0                64.67       1.0   \n",
       "19            NaN     65.0       78.0     49.0                64.00       1.0   \n",
       "20            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "21            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "22            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "23            NaN     70.0       57.0     84.0                70.33       1.0   \n",
       "24            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "25            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "26            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "27            NaN      NaN        NaN      NaN                  NaN       NaN   \n",
       "28       Advanced      NaN        NaN      NaN                  NaN       NaN   \n",
       "29            NaN     61.0       79.0      NaN                  NaN       NaN   \n",
       "\n",
       "    Speaking  HSK Oral Pass  Scholarship        Program  \n",
       "0        NaN            NaN            0       Master's  \n",
       "1        NaN            NaN            0  Undergraduate  \n",
       "2        NaN            NaN            0     Non-degree  \n",
       "3        NaN            NaN            0       Master's  \n",
       "4        NaN            NaN            0     Non-degree  \n",
       "5        NaN            NaN            0     Non-degree  \n",
       "6        NaN            NaN            0       Doctoral  \n",
       "7        NaN            NaN            0     Non-degree  \n",
       "8        NaN            NaN            0       Master's  \n",
       "9        NaN            NaN            0       Master's  \n",
       "10       NaN            NaN            0       Doctoral  \n",
       "11       NaN            NaN            1     Non-degree  \n",
       "12       NaN            NaN            0     Non-degree  \n",
       "13       NaN            NaN            0     Non-degree  \n",
       "14       NaN            NaN            0     Non-degree  \n",
       "15       NaN            NaN            0  Undergraduate  \n",
       "16       NaN            NaN            0       Master's  \n",
       "17       NaN            NaN            0     Non-degree  \n",
       "18       NaN            NaN            0  Undergraduate  \n",
       "19       NaN            NaN            0     Non-degree  \n",
       "20       NaN            NaN            0       Master's  \n",
       "21       NaN            NaN            0       Master's  \n",
       "22       NaN            NaN            0       Doctoral  \n",
       "23       NaN            NaN            0       Master's  \n",
       "24       NaN            NaN            0     Non-degree  \n",
       "25       NaN            NaN            0  Undergraduate  \n",
       "26       NaN            NaN            0     Non-degree  \n",
       "27       NaN            NaN            0     Non-degree  \n",
       "28      66.0            1.0            0     Non-degree  \n",
       "29       NaN            NaN            1  Undergraduate  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_class_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "* Tidy up code.\n",
    "* Write up in more detail what each piece means and its implications.\n",
    "* Sort out references throughout.\n",
    "* Write README.\n",
    "* Include a tidy version of the entire code at the top of the notebook.\n",
    "* Visualize the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "https://ejournals.bc.edu/index.php/ihe/article/download/10945/9333/\n",
    "\n",
    "Includes some statistics on education background and funding.\n",
    "\n",
    "http://en.moe.gov.cn/documents/reports/201904/t20190418_378692.html\n",
    "\n",
    "More information on funding, origin country, where they studied, education background.\n",
    "\n",
    "https://www.researchgate.net/figure/Descriptive-statistics-of-general-proficiency-measured-by-HSK_tbl1_312107625\n",
    "https://www.researchgate.net/figure/Correlations-among-proficiency-subskills-and-total-scores-of-pre-HSK-and-post-HSK-data_tbl4_325299887\n",
    "\n",
    "109 US students measured on their Chinese proficiency upon returning to the US after 1 year in Beijing.\n",
    "\n",
    "https://www.kaggle.com/kerneler/starter-china-scholarship-data-may-8638c810-6\n",
    "\n",
    "Data on scholarships provided by Chinese universities.\n",
    "\n",
    "http://blog.sina.com.cn/s/blog_53e7c11d0101f02j.html\n",
    "\n",
    "Number of people that took HSK from 2009-2012\n",
    "\n",
    "http://global.chinadaily.com.cn/a/201905/31/WS5cf0b106a3104842260bee25.html\n",
    "6.8 million tests taken in 2018\n",
    "\n",
    "\n",
    "https://forum.duolingo.com/comment/30363109/Percentage-of-users-who-complete-their-tree-for-each-language\n",
    "Duolingo stats from 2019 suggesting 0.0124% complete the content. This covers 1000 characters, so not even HSK 4 level.\n",
    "\n",
    "https://www.statista.com/statistics/430717/china-foreign-students-by-country-of-origin/\n",
    "Foreign students by country of origin 2018.\n",
    "\n",
    "https://www.echinacities.com/china-news/Is-the-HSK-Level-6-Test-Too-Difficult-Foreign-Test-Takers-Seem-to-Think-So\n",
    "Why people don't go above level 4/5.\n",
    "\n",
    "https://educationdata.org/international-student-enrollment-statistics\n",
    "statistics on US students abraod"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
