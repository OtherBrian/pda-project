{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement\n",
    "For this project you must create a data set by simulating a real-world phenomenon of\n",
    "your choosing. You may pick any phenomenon you wish – you might pick one that is\n",
    "of interest to you in your personal or professional life. Then, rather than collect data\n",
    "related to the phenomenon, you should model and synthesise such data using Python.\n",
    "We suggest you use the numpy.random package for this purpose.\n",
    "Specifically, in this project you should:\n",
    "\n",
    "* Choose a real-world phenomenon that can be measured and for which you could\n",
    "collect at least one-hundred data points across at least four different variables.\n",
    "* Investigate the types of variables involved, their likely distributions, and their\n",
    "relationships with each other.\n",
    "* Synthesise/simulate a data set as closely matching their properties as possible.\n",
    "* Detail your research and implement the simulation in a Jupyter notebook – the\n",
    "data set itself can simply be displayed in an output cell within the notebook.\n",
    "\n",
    "Note that this project is about simulation – you must synthesise a data set. Some\n",
    "students may already have some real-world data sets in their own files. It is okay to\n",
    "base your synthesised data set on these should you wish (please reference it if you do),\n",
    "but the main task in this project is to create a synthesised data set. The next section\n",
    "gives an example project idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial thoughts - Only a fraction of International students in China get to the HSK 5 or 6.\n",
    "\n",
    "Despite the large number of international students in China, the minority attempt a standardized test (HSK). Even then, the bulk of people that do these tests go for HSK 4 or HSK 5, with HSK 6 having a noticable drop off. This is likely due to HSK 5 being an entry requirement for most college degrees in China, and so anything below HSK 4 or 5 is seen as having little value, whereas the exponential difficulty gap between each level means that HSK 6 is a large commitment to aim towards. Of those that do attempt the HSK though, the pass rate is quite high - likely due to preparation classes available as extras in Chinese universities and schools.\n",
    "\n",
    "I will also be highlighting the distribution of countries that students come from, with South Korea being the clear leader.\n",
    "\n",
    "\n",
    "## Variables\n",
    "\n",
    "* HSK level (see if I can get statistics on how many are awarded)\n",
    "* Education background\n",
    "* Origin country\n",
    "* Funding of study\n",
    "* Level of program they enroll into\n",
    "* Hours of study\n",
    "* Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country of Origin\n",
    "\n",
    "Turns out I only have access to the top 15 countries from 2018\n",
    "\n",
    "* South Korea\t50,600\n",
    "* Thailand\t28,608\n",
    "* Pakistan\t28,023\n",
    "* India\t23,198\n",
    "* United States\t20,996\n",
    "* Russia\t19,239\n",
    "* Indonesia\t15,050\n",
    "* Laos\t14,645\n",
    "* Japan\t14,230\n",
    "* Kazakhstan\t11,784\n",
    "* Vietnam\t11,299\n",
    "* Bangladesh\t10,735\n",
    "* France\t10,695\n",
    "* Mongolia\t10,158\n",
    "* Malaysia\t9,479"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.researchcghe.org/perch/resources/publications/to-publish-wp46.pdf\n",
    "\n",
    "Also has top 10 countries 2000-2016, and total international students. As I have HSK test data from 2012, if I follow these proportions I could estimate how many American students took on each of the tests. If I use the normal distribution of scores based on the earlier paper, I could simulate what students took on the HSK, what level and what score.\n",
    "\n",
    "It also has the % of students enrolled in fulltime degrees, etc. I know most degrees require HSK 5 at least in order to enrol, so I could extrapolate this out to make an educated guess on the number % of students in Chinese Language undergraduate degrees, as undergraduate Chinese language degrees would not require a HSK to enroll.\n",
    "\n",
    "It also shows how many students were receiving scholarships until 2013, and what proportion were for non-degree students. If I were to assume it grew at about the same rate as overall international students, and that it's shared proportionally between students from various countries, I could look at who was self-funded versus on scholarship.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2018 there were 492,185 International Students in China (http://global.chinadaily.com.cn/a/201904/12/WS5cb05c3ea3104842260b5eed.html#:~:text=Almost%20500%2C000%20international%20students%20studied,ministry%20said%20in%20a%20statement.)\n",
    "\n",
    "So based off of that number and the above breakdown we know that 278739 came from those 15 countries, therefore 213446 would come from \"Rest of the World\". At present I do not have a way to break these down further. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "I've since found that there were 81,562 African students in China in 2018 (https://www.studyinternational.com/news/african-students-china-alienated/). There's no breakdown by country though. This would bring rest of the world down to 131884.\n",
    "\n",
    "* Rest of the World 131,884\n",
    "* Africa 81,562\n",
    "* South Korea\t50,600\n",
    "* Thailand\t28,608\n",
    "* Pakistan\t28,023\n",
    "* India\t23,198\n",
    "* United States\t20,996\n",
    "* Russia\t19,239\n",
    "* Indonesia\t15,050\n",
    "* Laos\t14,645\n",
    "* Japan\t14,230\n",
    "* Kazakhstan\t11,784\n",
    "* Vietnam\t11,299\n",
    "* Bangladesh\t10,735\n",
    "* France\t10,695\n",
    "* Mongolia\t10,158\n",
    "* Malaysia\t9,479\n",
    "\n",
    "Going to work out proportions from each country\n",
    "\n",
    "World Population Dataset from https://data.worldbank.org/indicator/SP.POP.TOTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting African and Rest of the World countries.\n",
    "\n",
    "I'm going to use data from the World Bank to find out what proportion of the African population each country of African has, and I'll use this as the probability of the student coming from that country. This isn't a perfect measure, as in the real world there'd be political and academic exchanges with particular countries, meanwhile some countries are more likely to have a population that can afford to go to China for self-funded study. Nonetheless, I prefer this route as I do not want the 54 countries of African treated as one unit.\n",
    "\n",
    "I will also be doing the same for the Rest of the World. This comes with the same caveats as the African countries in that they do not represent academic or political exchanges. That said, the countries with large populations that are not counted in this top 15 or the African countries do tend to have populations that may afford studying abroad. For example Germany would be one of the remaining countries with a larger population, and so it's probability will be higher than others, however in real life its population is also likely to be more able to afford self-funded study in China."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can alter this to change the school size\n",
    "school_size = 2000\n",
    "\n",
    "seed = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#read_csv documentation https://pandas.pydata.org/pandas-docs/dev/reference/api/pandas.read_csv.html\n",
    "#I've edited this dataset to remove aggregations (e.g. Eurozone, World).\n",
    "#as well as China, Hong Kong and Macau - as these would not be considered International Students.\n",
    "populations_df = pd.read_csv('world_populations.csv', usecols = ['Country Name', 'Country Code', '2019'])\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "populations_df.dropna(inplace=True)\n",
    "\n",
    "populations_df['2019'] = populations_df['2019'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-2b154112fff5>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  african_countries['Proportion of African Population'] = african_countries['2019'] / africa_total_population\n"
     ]
    }
   ],
   "source": [
    "#Country Codes\n",
    "african_country_codes = ['DZA','AGO','BWA','IOT','BDI','CMR','CPV','CAF','TCD',\n",
    "                     'COM','MYT','COG','COD','BEN','GNQ','ETH','ERI','ATF',\n",
    "                     'DJI','GAB','GMB','GHA','GIN','CIV','KEN','LSO','LBR',\n",
    "                     'LBY','MDG','MWI','MLI','MRT','MUS','MAR','MOZ','NAM',\n",
    "                     'NER','NGA','GNB','REU','RWA','SHN','STP','SEN','SYC',\n",
    "                     'SLE','SOM','ZAF','ZWE','SSD','SDN','ESH','SWZ','TGO',\n",
    "                     'TUN','UGA','EGY','TZA','BFA','ZMB']\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html\n",
    "african_countries = populations_df.loc[populations_df['Country Code'].isin(african_country_codes)]\n",
    "\n",
    "#Get the sum of african population to work out proportions per country in a moment.\n",
    "africa_total_population = african_countries['2019'].sum()\n",
    "\n",
    "african_countries['Proportion of African Population'] = african_countries['2019'] / africa_total_population\n",
    "\n",
    "african_country = np.array(african_countries['Country Name'])\n",
    "african_probabilities = np.array(african_countries['Proportion of African Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.30460644e-02, 2.44280173e-02, 9.05816334e-03, 1.76823970e-03,\n",
       "       1.55980007e-02, 8.85048222e-03, 4.22111458e-04, 1.98618318e-02,\n",
       "       3.64224310e-03, 1.22402813e-02, 6.53111241e-04, 6.66174962e-02,\n",
       "       4.12989549e-03, 1.97391471e-02, 7.47271643e-04, 7.70544808e-02,\n",
       "       1.04080887e-03, 8.81265656e-04, 8.60278326e-02, 1.66759797e-03,\n",
       "       1.80201952e-03, 2.33477148e-02, 9.80277537e-03, 1.47443459e-03,\n",
       "       4.03539989e-02, 1.63128365e-03, 3.78976086e-03, 5.20214234e-03,\n",
       "       2.07007255e-02, 1.42987945e-02, 1.50888380e-02, 3.47377079e-03,\n",
       "       9.71516844e-04, 2.79944932e-02, 2.33079395e-02, 1.91471664e-03,\n",
       "       1.78925144e-02, 1.54252844e-01, 9.69201865e-03, 1.65069693e-04,\n",
       "       1.25085364e-02, 7.49336396e-05, 5.99715889e-03, 1.18534502e-02,\n",
       "       4.49473424e-02, 8.49090283e-03, 3.28619897e-02, 4.45230265e-02,\n",
       "       6.20375007e-03, 8.97646975e-03, 3.39798392e-02, 1.37095210e-02,\n",
       "       1.12413646e-02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "african_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2961247792"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Need to remove the top 15 countries from rest of the world too\n",
    "\n",
    "top_15_country_codes = ['KOR', 'THA', 'PAK', 'IND', 'USA', 'RUS', 'IDN', 'LAO', 'JPN', 'KAZ', 'VNM', 'BGD', 'FRA', 'MNG', 'MYS']\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isin.html\n",
    "top_15_countries = populations_df.loc[populations_df['Country Code'].isin(top_15_country_codes)]\n",
    "\n",
    "#Get the sum of african population to work out proportions per country in a moment.\n",
    "top_15_total_population = top_15_countries['2019'].sum()\n",
    "\n",
    "top_15_total_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to work out the rest of the world\n",
    "\n",
    "#World Population without China, Hong Kong & Macau, minus the African population, minus the top 15 countries\n",
    "rest_of_world_population = 6267671127 - africa_total_population - top_15_total_population\n",
    "\n",
    "rest_of_world = populations_df.loc[~populations_df['Country Code'].isin(african_country_codes)]\n",
    "rest_of_world = rest_of_world.loc[~rest_of_world['Country Code'].isin(top_15_country_codes)]\n",
    "\n",
    "\n",
    "rest_of_world['Proportion of World Population'] = rest_of_world['2019'] / rest_of_world_population\n",
    "\n",
    "rest_of_world.head()\n",
    "\n",
    "rest_of_world_country = np.array(rest_of_world['Country Name'])\n",
    "rest_of_world_probabilities = np.array(rest_of_world['Proportion of World Population'])\n",
    "\n",
    "#Probabilities do not add up to 1.0 right now, likely due to my removal of countries. \n",
    "#Need to plug the gap, and will assign it as the country \"Other\"\n",
    "other = 1 - sum(rest_of_world_probabilities)\n",
    "\n",
    "#Add \"Other\" into the selection and probabilties\n",
    "rest_of_world_country = np.insert(rest_of_world_country, -1, 'Other')\n",
    "rest_of_world_probabilities = np.insert(rest_of_world_probabilities, -1,  other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the probabilities and country names set up for the African and Rest of the World countries, I can use np.random.choice() to pick a student origin from the 17 regions (top 15 countries, Africa and Rest of the world). If Africa or Rest of the World is selected, it can then pick a country from those subsections.\n",
    "\n",
    "Now I'll need to get the probabilities of each of the 17 regions to be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.choice.html#numpy.random.Generator.choice\n",
    "\n",
    "student_origins = np.array(['Rest of the World', 'Africa', 'South Korea', 'Thailand', 'Pakistan', 'India', 'United States',\n",
    "                  'Russia', 'Indonesia', 'Laos', 'Japan', 'Kazakhstan', 'Vietnam', 'Bangladesh', 'France', 'Mongolia',\n",
    "                  'Malaysia'])\n",
    "\n",
    "#Count of students from each region in 2018\n",
    "student_origin_counts = np.array([131884, 81562, 50600, 28608, 28023, 23198, 20996, 19239, 15050, 14645, 14230, 11784,\n",
    "                        11299, 10735, 10695, 10158, 9479])\n",
    "\n",
    "\n",
    "#Work out the probability that a student came from each region\n",
    "student_origin_probabilities = student_origin_counts / sum(student_origin_counts)\n",
    "\n",
    "sum(student_origin_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try pick a country location for each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pakistan', 'Africa', 'Pakistan', ..., 'Rest of the World',\n",
       "       'United States', 'Rest of the World'], dtype='<U17')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "students = rng.choice(student_origins, school_size, p=student_origin_probabilities)\n",
    "\n",
    "students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rest = rng.choice(rest_of_world_country, 139, p=rest_of_world_probabilities)\n",
    "\n",
    "other = 1 - sum(rest_of_world_probabilities)\n",
    "#rest\n",
    "rest_of_world_country = np.insert(rest_of_world_country, -1, 'Other')\n",
    "rest_of_world_probabilities = np.insert(rest_of_world_probabilities, -1,  other)\n",
    "\n",
    "sum(rest_of_world_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nationality      \n",
       "South Korea          204\n",
       "Pakistan             116\n",
       "Thailand             113\n",
       "India                 89\n",
       "United States         87\n",
       "                    ... \n",
       "Jamaica                1\n",
       "Singapore              1\n",
       "Kosovo                 1\n",
       "Equatorial Guinea      1\n",
       "Papua New Guinea       1\n",
       "Length: 142, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "#Creating an index of student IDs to use for this\n",
    "index = np.arange(0,school_size)\n",
    "\n",
    "#Create the dataframe\n",
    "chinese_class_df = pd.DataFrame(index = index, columns = ['Nationality'])\n",
    "#Generate the countries\n",
    "chinese_class_df['Nationality'] = rng.choice(student_origins, school_size, p=student_origin_probabilities)\n",
    "\n",
    "#Trying to ensure the amount of African countries selected is automatically generated\n",
    "# https://stackoverflow.com/questions/49471442/using-pandas-value-counts-to-get-one-value\n",
    "\n",
    "#african_picks = (chinese_class_df['Nationality'].values == 'Africa').sum()\n",
    "\n",
    "#Iterating over rows\n",
    "#African students have a country picked for them\n",
    "chinese_class_df.loc[chinese_class_df['Nationality'] == 'Africa', 'Nationality'] = rng.choice(african_country, (chinese_class_df['Nationality'].values == 'Africa').sum(), p=african_probabilities) \n",
    "\n",
    "#row_picks = (chinese_class_df['Nationality'].values == 'Rest of the World').sum()\n",
    "\n",
    "#Rest of the world students have a country picked for them\n",
    "chinese_class_df.loc[chinese_class_df['Nationality'] == 'Rest of the World', 'Nationality'] = rng.choice(rest_of_world_country, (chinese_class_df['Nationality'].values == 'Rest of the World').sum(), p=rest_of_world_probabilities) \n",
    "\n",
    "\n",
    "chinese_class_df.value_counts()\n",
    "#african_students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who sat the HSK tests?\n",
    "\n",
    "Use 2012 figures for HSK test compared to International Students in China. Extrapolate what those numbers would be for 2018. Use the proportion that sat the tests as the success probability for a bernoulli distribution (via np.random.binomial).\n",
    "\n",
    "Taken from Sina Weibo: 2009-2012 HSK takers - http://blog.sina.com.cn/s/blog_53e7c11d0101f02j.html\n",
    "![here](https://screenshot.click/01_14-ryey4-tgwud.jpg)\n",
    "\n",
    "Important to note that the current version of the HSK tests was introduced in 2010, so a sharp increase in the first few years isn't a surprise. (Wikipedia references the history - https://en.wikipedia.org/wiki/Hanyu_Shuiping_Kaoshi#Between_2010%E2%80%932020)\n",
    "\n",
    "Also worthwhile noting that the table above doesn't specify students that took multiple HSK tests. For example someone could reasonably do HSK 1, 2 and 3 within the same year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the numbers that sat the test within China (国内).\n",
    "\n",
    "First let's look at the written HSK exams.\n",
    "* HSK 一级\n",
    "* HSK 二级\n",
    "* HSK 三级\n",
    "* HSK 四级\n",
    "* HSK 五级\n",
    "* HSK 六级\n",
    "\n",
    "I'm going to calculate the annual total written HSK tests taken in each of these years, and compare to the number of international students in China for each year (from page 36 of https://www.researchcghe.org/perch/resources/publications/to-publish-wp46.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total students taking HSK written exam in 2010: 17866\n",
      "Total students taking HSK written exam in 2011: 46161\n",
      "Total students taking HSK written exam in 2012: 60593\n",
      "Proportion of international students taking HSK written exam in 2010: 0.06739597872420687\n",
      "Proportion of international students taking HSK written exam in 2011: 0.15775551841865137\n",
      "Proportion of international students taking HSK written exam in 2012: 0.18454908171656564\n"
     ]
    }
   ],
   "source": [
    "hsk_written_2010 = 146 + 210 + 1171 + 3842 + 6931 + 5566\n",
    "hsk_written_2011 = 274 + 755 + 2504 + 11635 + 18018 + 12975\n",
    "hsk_written_2012 = 658 + 1343 + 4003 + 16158 + 21278 + 17153\n",
    "\n",
    "print(\"Total students taking HSK written exam in 2010: \" + str(hsk_written_2010))\n",
    "print(\"Total students taking HSK written exam in 2011: \" + str(hsk_written_2011))\n",
    "print(\"Total students taking HSK written exam in 2012: \" + str(hsk_written_2012))\n",
    "\n",
    "total_international_students_2010 = 265090\n",
    "total_international_students_2011 = 292611\n",
    "total_international_students_2012 = 328330\n",
    "\n",
    "print(\"Proportion of international students taking HSK written exam in 2010: \" + str(hsk_written_2010 / total_international_students_2010))\n",
    "print(\"Proportion of international students taking HSK written exam in 2011: \" + str(hsk_written_2011 / total_international_students_2011))\n",
    "print(\"Proportion of international students taking HSK written exam in 2012: \" + str(hsk_written_2012 / total_international_students_2012))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As 2012 is the latest year I can find for these types of figures, I will extrapolate the 2012 proportion to the number of international students in 2018. \n",
    "\n",
    "There were 492,185 international students in 2018, and if 18.5% took a HSK test we can expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated total students taking HSK written exam in 2018: 91054.0\n"
     ]
    }
   ],
   "source": [
    "hsk_written_total_2018 = 492185 * 0.185\n",
    "print(\"Estimated total students taking HSK written exam in 2018: \" + str(round(hsk_written_total_2018,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see how many of my students sat a written HSK exam in 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1632\n",
       "1     368\n",
       "Name: HSK written test?, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "#https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.binomial.html#numpy.random.Generator.binomial\n",
    "chinese_class_df['HSK written test?'] = rng.binomial(1, 0.185, school_size)\n",
    "\n",
    "chinese_class_df['HSK written test?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the oral exams\n",
    "* HSK 初级\n",
    "* HSK 中级\n",
    "* HSK 高级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total students taking HSK oral exam in 2010: 1023\n",
      "Total students taking HSK oral exam in 2011: 1886\n",
      "Total students taking HSK oral exam in 2012: 3171\n",
      "Proportion of international students taking HSK oral exam in 2010: 0.0038590667320532648\n",
      "Proportion of international students taking HSK oral exam in 2011: 0.00644541729463349\n",
      "Proportion of international students taking HSK oral exam in 2012: 0.00965796607072153\n"
     ]
    }
   ],
   "source": [
    "hsk_oral_2010 = 51 + 300 + 672\n",
    "hsk_oral_2011 = 67 + 506 + 1313\n",
    "hsk_oral_2012 = 56 + 1708 + 1407\n",
    "\n",
    "print(\"Total students taking HSK oral exam in 2010: \" + str(hsk_oral_2010))\n",
    "print(\"Total students taking HSK oral exam in 2011: \" + str(hsk_oral_2011))\n",
    "print(\"Total students taking HSK oral exam in 2012: \" + str(hsk_oral_2012))\n",
    "\n",
    "total_international_students_2010 = 265090\n",
    "total_international_students_2011 = 292611\n",
    "total_international_students_2012 = 328330\n",
    "\n",
    "print(\"Proportion of international students taking HSK oral exam in 2010: \" + str(hsk_oral_2010 / total_international_students_2010))\n",
    "print(\"Proportion of international students taking HSK oral exam in 2011: \" + str(hsk_oral_2011 / total_international_students_2011))\n",
    "print(\"Proportion of international students taking HSK oral exam in 2012: \" + str(hsk_oral_2012 / total_international_students_2012))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I'll use the 2012 figure, and round it up to 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated total students taking HSK oral exam in 2018: 4922.0\n"
     ]
    }
   ],
   "source": [
    "hsk_oral_total_2018 = 492185 * 0.01\n",
    "print(\"Estimated total students taking HSK oral exam in 2018: \" + str(round(hsk_oral_total_2018,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see how many of my students sat the HSK oral exam in 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1982\n",
       "1      18\n",
       "Name: HSK oral test?, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "#https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.binomial.html#numpy.random.Generator.binomial\n",
    "chinese_class_df['HSK oral test?'] = rng.binomial(1, 0.01, school_size)\n",
    "\n",
    "chinese_class_df['HSK oral test?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did any students sit both the written and oral exams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nationality</th>\n",
       "      <th>HSK written test?</th>\n",
       "      <th>HSK oral test?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>Egypt, Arab Rep.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>Iraq</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1940</th>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Nationality  HSK written test?  HSK oral test?\n",
       "542   Egypt, Arab Rep.                  1               1\n",
       "1209              Iraq                  1               1\n",
       "1940     United States                  1               1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_class_df.loc[(chinese_class_df['HSK written test?'] == 1) & (chinese_class_df['HSK oral test?'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who sat which exam?\n",
    "\n",
    "Look at the proportion of folks that did Hsk 1-6, and HSK beginner-advanced to use as probabilities. If a student has 1 in the oral or written test columns, np.random.choice based on the probabilities. As I'll be extrapolating 2012 figures for 2018, I'll use the 2012 ratios here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01085934, 0.02216428, 0.06606374, 0.26666447, 0.35116268,\n",
       "       0.2830855 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the 2012 figures to work out what proportion of HSK takers sat each level that year.\n",
    "\n",
    "#Listing the 6 HSK levels for the written exam\n",
    "hsk_written_levels = np.array(['HSK1', 'HSK2', 'HSK3', 'HSK4', 'HSK5', 'HSK6'])\n",
    "\n",
    "#Dividing the 2012 figures for each level by total HSK tests taken that year. These proportions will be my probabilities\n",
    "hsk_written_levels_proportions = np.array([658, 1343, 4003, 16158, 21278, 17153]) / hsk_written_2012\n",
    "\n",
    "hsk_written_levels_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these proportions to estimate how many of our estimated 91054 HSK written exam takers took each level in 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated HSK 1 takers in 2018: 989.0\n",
      "Estimated HSK 2 takers in 2018: 2018.0\n",
      "Estimated HSK 3 takers in 2018: 6015.0\n",
      "Estimated HSK 4 takers in 2018: 24281.0\n",
      "Estimated HSK 5 takers in 2018: 31975.0\n",
      "Estimated HSK 6 takers in 2018: 25776.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated HSK 1 takers in 2018: \" + str(round(hsk_written_levels_proportions[0] * 91054, 0)))\n",
    "print(\"Estimated HSK 2 takers in 2018: \" + str(round(hsk_written_levels_proportions[1] * 91054, 0)))\n",
    "print(\"Estimated HSK 3 takers in 2018: \" + str(round(hsk_written_levels_proportions[2] * 91054, 0)))\n",
    "print(\"Estimated HSK 4 takers in 2018: \" + str(round(hsk_written_levels_proportions[3] * 91054, 0)))\n",
    "print(\"Estimated HSK 5 takers in 2018: \" + str(round(hsk_written_levels_proportions[4] * 91054, 0)))\n",
    "print(\"Estimated HSK 6 takers in 2018: \" + str(round(hsk_written_levels_proportions[5] * 91054, 0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to use these proportions as my probabilities to estimate what level each of my school's HSK takers attempted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HSK5    130\n",
       "HSK6    108\n",
       "HSK4     99\n",
       "HSK3     22\n",
       "HSK1      5\n",
       "HSK2      4\n",
       "Name: HSK Level, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only want students that have \"HSK written test?\" set as 1. First count how many there are to use as the size for rng.choice()\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK written test?'] == 1, 'HSK Level'] = rng.choice(hsk_written_levels, chinese_class_df['HSK written test?'].sum(), p=hsk_written_levels_proportions) \n",
    "\n",
    "chinese_class_df['HSK Level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to do the same for the oral test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01766004, 0.53863135, 0.44370861])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsk_oral_levels = np.array(['Beginner', 'Intermediate', 'Advanced'])\n",
    "hsk_oral_level_proportions = np.array([56, 1708, 1407]) / hsk_oral_2012\n",
    "\n",
    "hsk_oral_level_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, let's extrapolate this our for 2018. Early I estimated 4922 people sat a HSK oral test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated HSK Beginner takers in 2018: 87.0\n",
      "Estimated HSK Intermediate takers in 2018: 2651.0\n",
      "Estimated HSK Advanced takers in 2018: 2184.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated HSK Beginner takers in 2018: \" + str(round(hsk_oral_level_proportions[0] * 4922, 0)))\n",
    "print(\"Estimated HSK Intermediate takers in 2018: \" + str(round(hsk_oral_level_proportions[1] * 4922, 0)))\n",
    "print(\"Estimated HSK Advanced takers in 2018: \" + str(round(hsk_oral_level_proportions[2] * 4922, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see which oral tests the students in my school took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intermediate    13\n",
       "Advanced         4\n",
       "Beginner         1\n",
       "Name: HSK Oral Level, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only want students that have \"HSK oral test?\" set as 1. First count how many there are to use as the size for rng.choice()\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK oral test?'] == 1, 'HSK Oral Level'] = rng.choice(hsk_oral_levels, chinese_class_df['HSK oral test?'].sum(), p=hsk_oral_level_proportions) \n",
    "\n",
    "chinese_class_df['HSK Oral Level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSK Results\n",
    "\n",
    "For those students that sat the HSK tests, we can now simulate what their scores might be. Finding data on HSK scores and results has proven to be very difficult (both in Chinese and in English), however according there has been a study on 108 American students and their HSK results before and after a semester of study in Beijing (https://www.researchgate.net/figure/Descriptive-statistics-of-general-proficiency-measured-by-HSK_tbl1_312107625). It should be noted that this paper covers just 108 students from the same country, so in reality there's likely to be numerous other variables that may impact the results seen by a particular student or even a whole cohort of students. For example, Chinese textbooks will have grammar and other explanations written in English for HSK 1 through to HSK 3, and the quality of those translations, or how comparable the grammar rules are to the readers native language may influence how well they retain the information and therefore perform on the test. \n",
    "\n",
    "Similarly, all 108 students in this study took the HSK 4 written test and the intermediate oral test, so we do not have comparable results for the various other levels. That said, all of the tests follow a similar marking structure, with each section scored out of 100, and so for the purposes of this assignment I will be utilising the mean and standard deviation that was found among those 108 students.\n",
    "\n",
    "This is by no means a perfect simulation of the scores that I can expect at my fictional school, but with the absence of data on HSK test scores or pass/fail rates, it will have to suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSK Written Test Results\n",
    "\n",
    "https://www.chinaeducenter.com/en/exams.php\n",
    "\n",
    "The HSK written tests follow a similar structure, with each level becoming more difficult. Levels 1 and 2 do not include a writing section, as students at this level are not expected to be able to hand write a large number of characters, and so reading and listening skills are the only areas tested. For levels 3 through to 6; reading, writing and listening are each tested.\n",
    "\n",
    "For levels 1-5, the student must achieve at least 60% in order to pass the test. For HSK level 6, only a score of 40% is required. The HSK tests are a simple pass/fail grading system.\n",
    "\n",
    "As each of the tests includes a reading and listening portion scored out of 100, and as I will be using the mean and standard deviation from the above linked study to simulate the results regardless of level, I can use the same function for all the written HSK takers. For this I will use a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    340\n",
       "0.0     19\n",
       "Name: HSK Pass, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading results https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.normal.html#numpy.random.Generator.normal\n",
    "\n",
    "reading_mean = 75.39\n",
    "reading_sd = 13.85\n",
    "chinese_class_df.loc[chinese_class_df['HSK written test?'] == 1, 'Reading'] = rng.normal(reading_mean, reading_sd, chinese_class_df['HSK written test?'].sum())\n",
    "\n",
    "#Reducing the HSK6 results by 1/3 to reflect the higher difficulty. The mean and SD for HSK4 is too high for this test.\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK Level'] == 'HSK6', ['Reading']] = (chinese_class_df['Reading'] / 3) * 2\n",
    "\n",
    "#Normal distribution will pick a few values above 100. This goes beyond the possible score in the section, so I'll cap these at 100.\n",
    "chinese_class_df.loc[chinese_class_df['Reading'] > 100, 'Reading'] = 100\n",
    "\n",
    "\n",
    "#Listening test\n",
    "listening_mean = 70.73\n",
    "listening_sd = 15.22\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK written test?'] == 1, 'Listening'] = rng.normal(listening_mean, listening_sd, chinese_class_df['HSK written test?'].sum())\n",
    "chinese_class_df.loc[chinese_class_df['HSK Level'] == 'HSK6', ['Listening']] = (chinese_class_df['Listening'] / 3) * 2\n",
    "chinese_class_df.loc[chinese_class_df['Listening'] > 100, 'Listening'] = 100\n",
    "\n",
    "\n",
    "#Only HSK 3 - 6 has a writing section, so I'll make a mask to help me subset those tests.\n",
    "hsk_writing_sections = ['HSK3', 'HSK4', 'HSK5', 'HSK6']\n",
    "\n",
    "writing_mean = 69.67\n",
    "writing_sd = 11.95\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK Level'].isin(hsk_writing_sections), 'Writing'] = rng.normal(writing_mean, writing_sd, len(chinese_class_df.loc[chinese_class_df['HSK Level'].isin(hsk_writing_sections)]))\n",
    "chinese_class_df.loc[chinese_class_df['HSK Level'] == 'HSK6', ['Writing']] = (chinese_class_df['Writing'] / 3) * 2\n",
    "chinese_class_df.loc[chinese_class_df['Writing'] > 100, 'Writing'] = 100\n",
    "\n",
    "#Combined the 3 sections to get the score\n",
    "chinese_class_df['Total Written Score'] = chinese_class_df['Reading'] + chinese_class_df['Listening'] + chinese_class_df['Writing']\n",
    "\n",
    "#HSK 3 - 6 has 3 sections, so final score has to be divided by 3.\n",
    "chinese_class_df.loc[chinese_class_df['HSK Level'].isin(hsk_writing_sections), 'Total Written Score'] = chinese_class_df['Total Written Score'] / 3\n",
    "\n",
    "chinese_class_df.loc[~chinese_class_df['HSK Level'].isin(hsk_writing_sections), 'Total Written Score'] = chinese_class_df['Total Written Score'] / 2\n",
    "\n",
    "hsk_pass_60_tests = ['HSK1','HSK2','HSK3','HSK4','HSK5']\n",
    "\n",
    "chinese_class_df.loc[(chinese_class_df['HSK Level'].isin(hsk_pass_60_tests)) & (chinese_class_df['Total Written Score'] >= 60), 'HSK Pass'] = 1\n",
    "chinese_class_df.loc[(chinese_class_df['HSK Level'].isin(hsk_pass_60_tests)) & (chinese_class_df['Total Written Score'] < 60), 'HSK Pass'] = 0\n",
    "chinese_class_df.loc[(~chinese_class_df['HSK Level'].isin(hsk_pass_60_tests)) & (chinese_class_df['Total Written Score'] >=40), 'HSK Pass'] = 1\n",
    "chinese_class_df.loc[(~chinese_class_df['HSK Level'].isin(hsk_pass_60_tests)) & (chinese_class_df['Total Written Score'] <40), 'HSK Pass'] = 0\n",
    "\n",
    "chinese_class_df['HSK Pass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSK Oral Test Results\n",
    "\n",
    "Unlike the written tests which have 2 or 3 distinct sections, the HSK Oral Test just tests spoken language skills, and so just has the 1 speaking section. The passing grade for this is 60% for all three levels of the oral test (beginner, intermiedate, advanced).\n",
    "\n",
    "The previous mentioned study for 108 students from the US also measured the results of the HSK Oral test for those students. One notable difference here is that due to the low participation rate of the HSK Oral test, a sample of 108 measurements is actually fairly sizable. Earlier in my extrapolation of 2012 trends to 2018 international student figures, we saw that only about 1% of students in China attempt the HSK Oral test. While the written HSK 4 is seen as the first valuable HSK certification, and HSK 5 is required for attending a college program in Chinese, the oral certifications have very few applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HSK written test?</th>\n",
       "      <th>HSK oral test?</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Listening</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Total Written Score</th>\n",
       "      <th>HSK Pass</th>\n",
       "      <th>Speaking</th>\n",
       "      <th>HSK Oral Pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>68.201168</td>\n",
       "      <td>64.108616</td>\n",
       "      <td>62.230958</td>\n",
       "      <td>64.757627</td>\n",
       "      <td>0.947075</td>\n",
       "      <td>77.711778</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.387581</td>\n",
       "      <td>0.094464</td>\n",
       "      <td>16.662135</td>\n",
       "      <td>17.144918</td>\n",
       "      <td>15.393732</td>\n",
       "      <td>13.239013</td>\n",
       "      <td>0.224196</td>\n",
       "      <td>9.486115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.117496</td>\n",
       "      <td>21.362975</td>\n",
       "      <td>23.886705</td>\n",
       "      <td>37.421959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.580590</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.649849</td>\n",
       "      <td>50.478581</td>\n",
       "      <td>50.043757</td>\n",
       "      <td>51.068796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69.648430</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.561277</td>\n",
       "      <td>64.158689</td>\n",
       "      <td>61.840258</td>\n",
       "      <td>67.823972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78.374923</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.185438</td>\n",
       "      <td>77.727972</td>\n",
       "      <td>72.301328</td>\n",
       "      <td>75.408398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>83.319830</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>92.846115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>95.568862</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HSK written test?  HSK oral test?     Reading   Listening     Writing  \\\n",
       "count        2000.000000     2000.000000  368.000000  368.000000  359.000000   \n",
       "mean            0.184000        0.009000   68.201168   64.108616   62.230958   \n",
       "std             0.387581        0.094464   16.662135   17.144918   15.393732   \n",
       "min             0.000000        0.000000   25.117496   21.362975   23.886705   \n",
       "25%             0.000000        0.000000   54.649849   50.478581   50.043757   \n",
       "50%             0.000000        0.000000   69.561277   64.158689   61.840258   \n",
       "75%             0.000000        0.000000   80.185438   77.727972   72.301328   \n",
       "max             1.000000        1.000000  100.000000  100.000000  100.000000   \n",
       "\n",
       "       Total Written Score    HSK Pass   Speaking  HSK Oral Pass  \n",
       "count           359.000000  359.000000  18.000000           18.0  \n",
       "mean             64.757627    0.947075  77.711778            1.0  \n",
       "std              13.239013    0.224196   9.486115            0.0  \n",
       "min              37.421959    0.000000  65.580590            1.0  \n",
       "25%              51.068796    1.000000  69.648430            1.0  \n",
       "50%              67.823972    1.000000  78.374923            1.0  \n",
       "75%              75.408398    1.000000  83.319830            1.0  \n",
       "max              92.846115    1.000000  95.568862            1.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsk_oral_mean = 79\n",
    "hsk_oral_sd = 9.84\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['HSK oral test?'] == 1, 'Speaking'] = rng.normal(hsk_oral_mean, hsk_oral_sd, chinese_class_df['HSK oral test?'].sum())\n",
    "chinese_class_df.loc[chinese_class_df['Speaking'] > 100, 'Speaking'] = 100\n",
    "\n",
    "chinese_class_df.loc[chinese_class_df['Speaking'] >= 60, 'HSK Oral Pass'] = 1\n",
    "chinese_class_df.loc[chinese_class_df['Speaking'] < 60, 'HSK Oral Pass'] = 0\n",
    "\n",
    "\n",
    "chinese_class_df.describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSK6 scores are too high. The mean for the HSK results is around 60, whereas pass for HSK6 is only 40. I will reduce the values by 1/3 to account for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSK results\n",
    "\n",
    "https://www.researchgate.net/figure/Descriptive-statistics-of-general-proficiency-measured-by-HSK_tbl1_312107625\n",
    "\n",
    "108 participants from the US did the intermedite spoken exam and HSK 4 written exam.\n",
    "\n",
    "These students stayed in the country for 1 semester (about 3 months).\n",
    "\n",
    "We also have the mean, min, max and std from that group.\n",
    "\n",
    "![here](https://screenshot.click/28_19-215cg-skgcm.jpg)\n",
    "\n",
    "I could use this to create a normal distribution of test scores from US students who have been studying in China. As I know what a passing score is, I could calculate if it was a pass or fail.\n",
    "\n",
    "Another source of data on HSK 4 results http://dpi-proceedings.com/index.php/dtem/article/view/30976/29557\n",
    "\n",
    "Shows the mean and std for 30 students from Beijing Language & Culture University\n",
    "\n",
    "![here](https://screenshot.click/28_02-0i7p9-b37me.jpg)\n",
    "\n",
    "\n",
    "\n",
    "Some more results for 2010 including pass rates and average scores for each HSK level http://www.chinesetest.cn/gonewcontent.do?id=5589387 (Note - these are for tests taken outside China)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "* Add variables to show who is self-funded versus who is on a scholarship of some sort.\n",
    "* Also look at who is on degree vs non-degree.\n",
    "* May also be able to look at their education background too.\n",
    "\n",
    "\n",
    "## Potential data points\n",
    "* Country - np.random.choice with probabilities for top 15 countries\n",
    "* Course type - degree vs non-degree - binomial with 1 meaning degree\n",
    "* Self-funded / scholarship - binomial with 1 meaning scholarship\n",
    "* Attempted HSK written - binomial\n",
    "* Level attempted - np.random.choice\n",
    "* Attempt HSK spoken - binomial\n",
    "* Level attempted - np.random.choice\n",
    "* Results for each section - normal distributions for each\n",
    "* Total score - total of the results of each section\n",
    "* Pass/Fail - total compared to required pass score for that level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "https://ejournals.bc.edu/index.php/ihe/article/download/10945/9333/\n",
    "\n",
    "Includes some statistics on education background and funding.\n",
    "\n",
    "http://en.moe.gov.cn/documents/reports/201904/t20190418_378692.html\n",
    "\n",
    "More information on funding, origin country, where they studied, education background.\n",
    "\n",
    "https://www.researchgate.net/figure/Descriptive-statistics-of-general-proficiency-measured-by-HSK_tbl1_312107625\n",
    "https://www.researchgate.net/figure/Correlations-among-proficiency-subskills-and-total-scores-of-pre-HSK-and-post-HSK-data_tbl4_325299887\n",
    "\n",
    "109 US students measured on their Chinese proficiency upon returning to the US after 1 year in Beijing.\n",
    "\n",
    "https://www.kaggle.com/kerneler/starter-china-scholarship-data-may-8638c810-6\n",
    "\n",
    "Data on scholarships provided by Chinese universities.\n",
    "\n",
    "http://blog.sina.com.cn/s/blog_53e7c11d0101f02j.html\n",
    "\n",
    "Number of people that took HSK from 2009-2012\n",
    "\n",
    "http://global.chinadaily.com.cn/a/201905/31/WS5cf0b106a3104842260bee25.html\n",
    "6.8 million tests taken in 2018\n",
    "\n",
    "\n",
    "https://forum.duolingo.com/comment/30363109/Percentage-of-users-who-complete-their-tree-for-each-language\n",
    "Duolingo stats from 2019 suggesting 0.0124% complete the content. This covers 1000 characters, so not even HSK 4 level.\n",
    "\n",
    "https://www.statista.com/statistics/430717/china-foreign-students-by-country-of-origin/\n",
    "Foreign students by country of origin 2018.\n",
    "\n",
    "https://www.echinacities.com/china-news/Is-the-HSK-Level-6-Test-Too-Difficult-Foreign-Test-Takers-Seem-to-Think-So\n",
    "Why people don't go above level 4/5.\n",
    "\n",
    "https://educationdata.org/international-student-enrollment-statistics\n",
    "statistics on US students abraod"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
